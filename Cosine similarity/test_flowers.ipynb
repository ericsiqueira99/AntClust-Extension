{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bfa61f-7e98-469d-a348-4d61c8813f96",
   "metadata": {},
   "source": [
    "# Clustering of Similar Images\n",
    "\n",
    "In this example we try to cluster images of flowers from the 10 Category Flower Dataset (https://www.kaggle.com/datasets/olgabelitskaya/flower-color-images) clustered.  \n",
    "\n",
    "The idea is that it can cluster images from different classes using a cosine similarity from a pretrained CLIP model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d8cf29-fd1a-4b8e-9038-b1e59552630d",
   "metadata": {},
   "source": [
    "### Data functions\n",
    "These functions are needed to load the images from the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07fe4fea-be52-48a4-8b18-fa63f70a8717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "path_img = \"flower_images/\"\n",
    "df = pd.read_csv(f\"{path_img}flower_labels.csv\")\n",
    "# we'll test with a subset of the dataset first\n",
    "image_names = list(glob.glob(f'{path_img}*.png'))\n",
    "subset = len(image_names)\n",
    "image_names = list(glob.glob(f'{path_img}*.png'))[:subset]\n",
    "true_labels = list(df[\"label\"])[:subset]\n",
    "image_names = [name.split(\"\\\\\")[-1] for name in image_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291b511-9f21-4d14-91cf-4f60c5edcf24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AntClust Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7678567c-35d6-4754-9a9a-d1024c915d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de36ed7b55f440a4aa960f0eefd57ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------\n",
    "#       imports\n",
    "# ----------------------\n",
    "# import opencv\n",
    "import cv2 as cv\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make AntClus dir known\n",
    "import sys\n",
    "sys.path.append(\"../AntClust\")\n",
    "# import AntClust\n",
    "from AntClust import AntClust\n",
    "# import the precomputed distance matrix function for AntClust\n",
    "from distance_classes import image_cosine_similarity\n",
    "# import the rule set\n",
    "from rules import labroche_rules\n",
    "\n",
    "# ----------------------\n",
    "#       data\n",
    "# ----------------------\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "#       AntClust\n",
    "# ----------------------\n",
    "# tell AntClust to treat the data set as precomputed similarity matrix\n",
    "# similarity function\n",
    "path_img = \"../Cosine similarity/flower_images/\"\n",
    "f_sim = [image_cosine_similarity(path_img,image_names)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d9df93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntClust: phase 1 of 3 -> meeting ants\n",
      "Meeting 15750 / 15750\n",
      "Meeting 14175 / 15750\n",
      "Meeting 12600 / 15750\n",
      "Meeting 11025 / 15750\n",
      "Meeting 9450 / 15750\n",
      "Meeting 7875 / 15750\n",
      "Meeting 6300 / 15750\n",
      "Meeting 4725 / 15750\n",
      "Meeting 3150 / 15750\n",
      "Meeting 1575 / 15750\n",
      "AntClust: phase 2 of 3 -> shrink nests\n",
      "AntClust: phase 3 of 3 -> reassign ants\n",
      "\n",
      "\n",
      "Accuracy 0.12857142857142856\n"
     ]
    }
   ],
   "source": [
    "ant_clust = AntClust(f_sim, labroche_rules())\n",
    "\n",
    "# find clusters by using the distance matrix of the data\n",
    "\n",
    "ant_clust.fit([[i] for i in range(subset)])\n",
    "\n",
    "# get the clustering result\n",
    "clusters_found = ant_clust.labels_\n",
    "clusters_found = ant_clust.get_clusters()\n",
    "\n",
    "print()\n",
    "#print(f'true labeling (x)   {true_labels}')\n",
    "#print(f'AntClust labels (y) {clusters_found}')\n",
    "print()\n",
    "correct = 0\n",
    "for i in range(len(true_labels)):\n",
    "    if true_labels[i] == clusters_found[i]:\n",
    "        correct +=1\n",
    "print(f\"Accuracy {correct/len(true_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e3a28-f5af-4214-a7f7-87fe4cfbaf6f",
   "metadata": {},
   "source": [
    "# K-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20ea07-43a8-4c5a-9146-346db3d9182d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Function to Extract features from the images\n",
    "def image_feature(direc):\n",
    "    model = InceptionV3(weights='imagenet', include_top=False)\n",
    "    features = []\n",
    "    img_name = []\n",
    "\n",
    "    for i in tqdm(direc, disable=True):\n",
    "        fname=\"../Cosine Similarity/flower_images/\"+i\n",
    "        img=image.load_img(fname,target_size=(224,224))\n",
    "        x = img_to_array(img)\n",
    "        x=np.expand_dims(x,axis=0)\n",
    "        x=preprocess_input(x)\n",
    "        feat=model.predict(x)\n",
    "        feat=feat.flatten()\n",
    "        features.append(feat)\n",
    "        img_name.append(i)\n",
    "    return features,img_name\n",
    "\n",
    "img_features,img_name=image_feature(image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5729d349-34b6-428a-b195-7c187c8f5b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.01904761904761905\n"
     ]
    }
   ],
   "source": [
    "#Creating Clusters\n",
    "k = 10 # number of classes in dataset\n",
    "clusters = KMeans(k, random_state = 40)\n",
    "clusters.fit(img_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aa0bdc",
   "metadata": {},
   "source": [
    "# AntClust with ORB similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d998f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orb_image_features(images, image_resize_size):\n",
    "    \"\"\"Computes and returns the OpenCV ORB image feature descriptors\"\"\"\n",
    "    # Initiate ORB detector for feature extraction\n",
    "    orb = cv.ORB_create()\n",
    "    descriptors = []\n",
    "    # compute key points and descriptors\n",
    "    for image in images:\n",
    "        img = image[0]\n",
    "        #img = cv.resize(img, image_resize_size)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        descriptors.append([des])\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75211f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "#       imports\n",
    "# ----------------------\n",
    "# import sklearn distance function\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "# import opencv\n",
    "import cv2 as cv\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make AntClus dir known\n",
    "import sys\n",
    "sys.path.append(\"../AntClust\")\n",
    "# import AntClust\n",
    "from AntClust import AntClust\n",
    "# import the precomputed distance matrix function for AntClust\n",
    "from distance_classes import precomputed_similarity_matrix, opencv_orb_similarity\n",
    "# import the rule set\n",
    "from rules import labroche_rules\n",
    "\n",
    "# ----------------------\n",
    "#       data\n",
    "# ----------------------\n",
    "image_resize_size = (553, 500)\n",
    "true_labels = list(df[\"label\"])[:subset]\n",
    "image_names = [name.split(\"\\\\\")[-1] for name in image_names]\n",
    "path_img = \"../Cosine Similarity/flower_images/\"\n",
    "image_data = []\n",
    "for image_file in image_names:\n",
    "    image_data.append(\n",
    "                [cv.imread(path_img + image_file, cv.IMREAD_GRAYSCALE)]\n",
    "            )\n",
    "image_orbs = compute_orb_image_features(image_data, image_resize_size)\n",
    "data = np.array(image_orbs, dtype=list)\n",
    "labels = np.array(true_labels)\n",
    "# distance matrix for sklearn\n",
    "orb_sim = opencv_orb_similarity()\n",
    "distance_matrix = []\n",
    "for i in range(len(data)):\n",
    "    t_l = []\n",
    "    for n in range(len(data)):\n",
    "        t_l.append(orb_sim.similarity(data[i][0], data[n][0]))\n",
    "    distance_matrix.append(t_l)\n",
    "\n",
    "# sklearn needs it in the way that 0 means a==b\n",
    "# ant clust needs it in the way 1 means a==b\n",
    "distance_matrix = 1 - np.array(distance_matrix)\n",
    "# AntClust needs every data tuple as an array.\n",
    "# e.g. [1,2,3] needs to be [[1],[2],[3]]\n",
    "distance_matrix = [[i] for i in distance_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a629c08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntClust: phase 1 of 3 -> meeting ants\n",
      "Meeting 15750 / 15750\n",
      "Meeting 14175 / 15750\n",
      "Meeting 12600 / 15750\n",
      "Meeting 11025 / 15750\n",
      "Meeting 9450 / 15750\n",
      "Meeting 7875 / 15750\n",
      "Meeting 6300 / 15750\n",
      "Meeting 4725 / 15750\n",
      "Meeting 3150 / 15750\n",
      "Meeting 1575 / 15750\n",
      "AntClust: phase 2 of 3 -> shrink nests\n",
      "AntClust: phase 3 of 3 -> reassign ants\n"
     ]
    }
   ],
   "source": [
    "# ----------------------\n",
    "#       AntClust\n",
    "# ----------------------\n",
    "# tell AntClust to treat the data set as precomputed similarity matrix\n",
    "# similarity function\n",
    "f_sim = [precomputed_similarity_matrix()]\n",
    "ant_clust = AntClust(f_sim, labroche_rules())\n",
    "\n",
    "# find clusters by using the distance matrix of the data\n",
    "ant_clust.fit(distance_matrix)\n",
    "\n",
    "# get the clustering result\n",
    "clusters_found_orb = ant_clust.get_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a774d",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f60ea3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI for AntClust (Cosine Similarity) 0.6389888868288874\n",
      "ARI for AntClust (ORB Similarity) 0.011252503833263665\n",
      "ARI for K-means (k=10) 0.23139984255616106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "ari_ant_cos = adjusted_rand_score(true_labels, clusters_found)\n",
    "ari_kmeans = adjusted_rand_score(true_labels, clusters.labels_)\n",
    "ari_ant_orb = adjusted_rand_score(true_labels, clusters_found_orb)\n",
    "\n",
    "print(f\"ARI for AntClust (Cosine Similarity) {ari_ant_cos}\")\n",
    "print(f\"ARI for AntClust (ORB Similarity) {ari_ant_orb}\")\n",
    "print(f\"ARI for K-means (k={k}) {ari_kmeans}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acc0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
