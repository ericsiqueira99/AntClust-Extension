{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Dataset\n",
    "Source: https://www.kaggle.com/datasets/census/retail-and-retailers-sales-time-series-collection\n",
    "\n",
    "Implementation based off : https://www.kaggle.com/code/izzettunc/introduction-to-time-series-clustering\n",
    "\n",
    "\n",
    "Idea is to apply clustering of time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\erics\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Native libraries\n",
    "import os\n",
    "import math\n",
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Algorithms\n",
    "from minisom import MiniSom\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = os.getcwd()+'/archive/'\n",
    "mySeries = []\n",
    "namesofMySeries = []\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(directory+filename)\n",
    "        df = df.loc[:,[\"date\",\"value\"]]\n",
    "        # While we are at it I just filtered the columns that we will be working on\n",
    "        df.set_index(\"date\",inplace=True)\n",
    "        # ,set the date columns as index\n",
    "        df.sort_index(inplace=True)\n",
    "        # and lastly, ordered the data according to our date index\n",
    "        mySeries.append(df)\n",
    "        namesofMySeries.append(filename[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Normalizing and filling empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{332, 333}\n",
      "[0] 1992-02-01 2019-09-01\n",
      "[1] 1992-01-01 2019-09-01\n",
      "[2] 1992-01-01 2019-09-01\n",
      "[3] 1992-01-01 2019-09-01\n",
      "[4] 1992-01-01 2019-09-01\n",
      "[5] 1992-01-01 2019-09-01\n",
      "[6] 1992-01-01 2019-09-01\n",
      "[7] 1992-01-01 2019-09-01\n",
      "[8] 1992-01-01 2019-09-01\n",
      "[9] 1992-01-01 2019-09-01\n",
      "[10] 1992-01-01 2019-09-01\n",
      "[11] 1992-01-01 2019-09-01\n",
      "[12] 1992-01-01 2019-09-01\n",
      "[13] 1992-01-01 2019-09-01\n",
      "[14] 1992-01-01 2019-09-01\n",
      "[15] 1992-01-01 2019-09-01\n",
      "[16] 1992-01-01 2019-09-01\n",
      "[17] 1992-01-01 2019-09-01\n",
      "[18] 1992-01-01 2019-09-01\n",
      "[19] 1992-02-01 2019-09-01\n",
      "[20] 1992-02-01 2019-09-01\n",
      "[21] 1992-01-01 2019-09-01\n",
      "[22] 1992-01-01 2019-09-01\n"
     ]
    }
   ],
   "source": [
    "series_lengths = {len(series) for series in mySeries}\n",
    "print(series_lengths)\n",
    "ind = 0\n",
    "for series in mySeries:\n",
    "    print(\"[\"+str(ind)+\"] \"+series.index[0]+\" \"+series.index[len(series)-1])\n",
    "    ind+=1\n",
    "\n",
    "max_len = max(series_lengths)\n",
    "longest_series = None\n",
    "for series in mySeries:\n",
    "    if len(series) == max_len:\n",
    "        longest_series = series\n",
    "\n",
    "problems_index = []\n",
    "\n",
    "for i in range(len(mySeries)):\n",
    "    if len(mySeries[i])!= max_len:\n",
    "        problems_index.append(i)\n",
    "        mySeries[i] = mySeries[i].reindex(longest_series.index)\n",
    "\n",
    "def nan_counter(list_of_series):\n",
    "    nan_polluted_series_counter = 0\n",
    "    for series in list_of_series:\n",
    "        if series.isnull().sum().sum() > 0:\n",
    "            nan_polluted_series_counter+=1\n",
    "    return nan_polluted_series_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Fix missing values------\n",
      "NaN values: 3\n",
      "------Perform interpolation------\n",
      "NaN values: 0\n",
      "------Normalizing values------\n",
      "max: 1.0\tmin: 0.0\n",
      "[0.53953488 0.53953488 0.59627907 0.54697674 0.54139535]\n"
     ]
    }
   ],
   "source": [
    "print(\"------Fix missing values------\")\n",
    "print(f\"NaN values: {nan_counter(mySeries)}\")\n",
    "print(\"------Perform interpolation------\")\n",
    "for i in problems_index:\n",
    "    mySeries[i].interpolate(limit_direction=\"both\",inplace=True)\n",
    "print(f\"NaN values: {nan_counter(mySeries)}\")\n",
    "\n",
    "print(\"------Normalizing values------\")\n",
    "for i in range(len(mySeries)):\n",
    "    scaler = MinMaxScaler()\n",
    "    mySeries[i] = MinMaxScaler().fit_transform(mySeries[i])\n",
    "    mySeries[i]= mySeries[i].reshape(len(mySeries[i]))\n",
    "print(\"max: \"+str(max(mySeries[0]))+\"\\tmin: \"+str(min(mySeries[0])))\n",
    "print(mySeries[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOM\n",
    "Self-organizing maps are a type of neural network that is trained using unsupervised learning to produce a low-dimensional representation of the input space of the training samples, called a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_x = som_y = math.ceil(math.sqrt(math.sqrt(len(mySeries))))\n",
    "# I didn't see its significance but to make the map square,\n",
    "# I calculated square root of map size which is \n",
    "# the square root of the number of series\n",
    "# for the row and column counts of som\n",
    "\n",
    "som = MiniSom(som_x, som_y,len(mySeries[0]), sigma=0.3, learning_rate = 0.1)\n",
    "\n",
    "som.random_weights_init(mySeries)\n",
    "som.train(mySeries, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MRTSSM444USS</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM442USN</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM442USS</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILMPCSMSA</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILIRSA</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM448USS</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILMPCSMNSA</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSMPCSM4400CUSN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44X72USS</th>\n",
       "      <td>Cluster 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILIMSA</th>\n",
       "      <td>Cluster 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44000USS</th>\n",
       "      <td>Cluster 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILSMSA</th>\n",
       "      <td>Cluster 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILSMNSA</th>\n",
       "      <td>Cluster 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM7221USN</th>\n",
       "      <td>Cluster 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44112USN</th>\n",
       "      <td>Cluster 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44111USN</th>\n",
       "      <td>Cluster 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44611USN</th>\n",
       "      <td>Cluster 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4413USS</th>\n",
       "      <td>Cluster 8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4453USN</th>\n",
       "      <td>Cluster 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4481USN</th>\n",
       "      <td>Cluster 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM45111USN</th>\n",
       "      <td>Cluster 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM45112USN</th>\n",
       "      <td>Cluster 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4541USS</th>\n",
       "      <td>Cluster 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cluster\n",
       "Series                      \n",
       "MRTSSM444USS       Cluster 1\n",
       "MRTSSM442USN       Cluster 1\n",
       "MRTSSM442USS       Cluster 1\n",
       "RETAILMPCSMSA      Cluster 2\n",
       "RETAILIRSA         Cluster 2\n",
       "MRTSSM448USS       Cluster 3\n",
       "RETAILMPCSMNSA     Cluster 4\n",
       "MRTSMPCSM4400CUSN  Cluster 4\n",
       "MRTSSM44X72USS     Cluster 5\n",
       "RETAILIMSA         Cluster 5\n",
       "MRTSSM44000USS     Cluster 5\n",
       "RETAILSMSA         Cluster 5\n",
       "RETAILSMNSA        Cluster 6\n",
       "MRTSSM7221USN      Cluster 6\n",
       "MRTSSM44112USN     Cluster 6\n",
       "MRTSSM44111USN     Cluster 6\n",
       "MRTSSM44611USN     Cluster 7\n",
       "MRTSSM4413USS      Cluster 8\n",
       "MRTSSM4453USN      Cluster 9\n",
       "MRTSSM4481USN      Cluster 9\n",
       "MRTSSM45111USN     Cluster 9\n",
       "MRTSSM45112USN     Cluster 9\n",
       "MRTSSM4541USS      Cluster 9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_map = []\n",
    "for idx in range(len(mySeries)):\n",
    "    winner_node = som.winner(mySeries[idx])\n",
    "    cluster_map.append((namesofMySeries[idx],f\"Cluster {winner_node[0]*som_y+winner_node[1]+1}\"))\n",
    "\n",
    "pd.DataFrame(cluster_map,columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kmeans \n",
    "\n",
    "Using Dynamic Time Warping Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "cluster_count = math.ceil(math.sqrt(len(mySeries))) \n",
    "# A good rule of thumb is choosing k as the square root of the number of points in the training data set in kNN\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "\n",
    "labels = km.fit_predict(mySeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 4, 0, 4, 4, 0, 4, 0, 4, 0, 0, 4, 1, 0, 0, 0, 3, 2, 3, 4,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Series</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MRTSSM448USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILIMSA</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM7221USN</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4541USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44X72USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44611USN</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM444USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILSMSA</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4413USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44000USS</th>\n",
       "      <td>Cluster 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM45112USN</th>\n",
       "      <td>Cluster 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILMPCSMNSA</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSMPCSM4400CUSN</th>\n",
       "      <td>Cluster 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILIRSA</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILMPCSMSA</th>\n",
       "      <td>Cluster 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4453USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM442USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM4481USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAILSMNSA</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM45111USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44112USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM44111USN</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRTSSM442USS</th>\n",
       "      <td>Cluster 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cluster\n",
       "Series                      \n",
       "MRTSSM448USS       Cluster 0\n",
       "RETAILIMSA         Cluster 0\n",
       "MRTSSM7221USN      Cluster 0\n",
       "MRTSSM4541USS      Cluster 0\n",
       "MRTSSM44X72USS     Cluster 0\n",
       "MRTSSM44611USN     Cluster 0\n",
       "MRTSSM444USS       Cluster 0\n",
       "RETAILSMSA         Cluster 0\n",
       "MRTSSM4413USS      Cluster 0\n",
       "MRTSSM44000USS     Cluster 0\n",
       "MRTSSM45112USN     Cluster 1\n",
       "RETAILMPCSMNSA     Cluster 2\n",
       "MRTSMPCSM4400CUSN  Cluster 2\n",
       "RETAILIRSA         Cluster 3\n",
       "RETAILMPCSMSA      Cluster 3\n",
       "MRTSSM4453USN      Cluster 4\n",
       "MRTSSM442USN       Cluster 4\n",
       "MRTSSM4481USN      Cluster 4\n",
       "RETAILSMNSA        Cluster 4\n",
       "MRTSSM45111USN     Cluster 4\n",
       "MRTSSM44112USN     Cluster 4\n",
       "MRTSSM44111USN     Cluster 4\n",
       "MRTSSM442USS       Cluster 4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fancy_names_for_labels = [f\"Cluster {label}\" for label in labels]\n",
    "pd.DataFrame(zip(namesofMySeries,fancy_names_for_labels),columns=[\"Series\",\"Cluster\"]).sort_values(by=\"Cluster\").set_index(\"Series\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AntClust \n",
    "Using Similarity based on Dynamic Time Warping Distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntClust: phase 1 of 3 -> meeting ants\n",
      "Meeting 1725 / 1725\n",
      "Meeting 1380 / 1725\n",
      "Meeting 1035 / 1725\n",
      "Meeting 690 / 1725\n",
      "Meeting 345 / 1725\n",
      "AntClust: phase 2 of 3 -> shrink nests\n",
      "AntClust: phase 3 of 3 -> reassign ants\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from fastdtw import fastdtw\n",
    "# ----------------------\n",
    "#       imports\n",
    "# ----------------------\n",
    "\n",
    "# make AntClus dir known\n",
    "import sys\n",
    "sys.path.append(\"../AntClust\")\n",
    "# import AntClust\n",
    "from AntClust import AntClust\n",
    "from importlib import reload\n",
    "import distance_classes\n",
    "reload(distance_classes)\n",
    "# import the rule set\n",
    "from rules import labroche_rules\n",
    "\n",
    "def get_pair_wise_dist():# Calculate the DTW distance and alignment path\n",
    "    distance_array = []\n",
    "    for serie in mySeries:\n",
    "        for serie2 in mySeries:\n",
    "            distance, path = fastdtw(serie, serie2)\n",
    "            distance_array.append(distance) \n",
    "\n",
    "    my_array = np.array(distance_array)\n",
    "    min_value = np.min(my_array)\n",
    "    max_value = np.max(my_array)\n",
    "    return min_value, max_value\n",
    "\n",
    "min, max = get_pair_wise_dist()\n",
    "\n",
    "f_sim = [distance_classes.similarity_time_series(min, max)]\n",
    "ant_clust = AntClust(f_sim, labroche_rules())\n",
    "ant = [[serie] for serie in mySeries]\n",
    "ant_clust.fit(ant)\n",
    "clusters_found = ant_clust.get_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Metrics\n",
    "\n",
    "**Silhouette Score**\n",
    "The silhouette score measures how well-separated the clusters are. It ranges from -1 to 1, where a higher value indicates better-defined clusters.\n",
    "It considers both the distance between points within the same cluster and the distance between points in different clusters\n",
    "\n",
    "**Davies-Bouldin Index**\n",
    "The Davies-Bouldin index measures the compactness and separation between clusters. Lower values indicate better clustering.\n",
    "It considers the average similarity ratio of each cluster with the cluster that is most similar to it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score AntClust: 0.42147042898916864\n",
      "Silhouette Score kmeans (k=5): 0.21701614139757278\n",
      "Silhouette Score SOM: 0.18650587683541964\n",
      "Davies-Bouldin Index AntClust: 0.7928378621103818\n",
      "Davies-Bouldin Index kmeans (k=5): 1.1387750470950317\n",
      "Davies-Bouldin Index SOM: 0.787120987840383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "\n",
    "som_label = []\n",
    "for idx in range(len(mySeries)):\n",
    "    winner_node = som.winner(mySeries[idx])\n",
    "    som_label.append(winner_node[0]*som_y+winner_node[1])\n",
    "\n",
    "silhouette_avg_k = silhouette_score(mySeries, labels)\n",
    "silhouette_avg_som = silhouette_score(mySeries, som_label)\n",
    "silhouette_avg_ant = silhouette_score(mySeries, clusters_found)\n",
    "\n",
    "db_index_k = davies_bouldin_score(mySeries, labels)\n",
    "db_index_som = davies_bouldin_score(mySeries, som_label)\n",
    "db_index_ant = davies_bouldin_score(mySeries, clusters_found)\n",
    "\n",
    "print(f\"Silhouette Score AntClust: {silhouette_avg_ant}\")\n",
    "print(f\"Silhouette Score kmeans (k={cluster_count}): {silhouette_avg_k}\")\n",
    "print(f\"Silhouette Score SOM: {silhouette_avg_som}\")\n",
    "\n",
    "print(f\"Davies-Bouldin Index AntClust: {db_index_ant}\")\n",
    "print(f\"Davies-Bouldin Index kmeans (k={cluster_count}): {db_index_k}\")\n",
    "print(f\"Davies-Bouldin Index SOM: {db_index_som}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Silhouette score</th>\n",
       "      <th>Davies-Bouldin Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AntClust (DTW distance)</th>\n",
       "      <td>0.421470</td>\n",
       "      <td>0.792838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K means (k=5)</th>\n",
       "      <td>0.217016</td>\n",
       "      <td>1.138775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Self Organizing Maps</th>\n",
       "      <td>0.186506</td>\n",
       "      <td>0.787121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Silhouette score  Davies-Bouldin Index\n",
       "AntClust (DTW distance)          0.421470              0.792838\n",
       "K means (k=5)                    0.217016              1.138775\n",
       "Self Organizing Maps             0.186506              0.787121"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "silhouette_avg_k = silhouette_score(mySeries, labels)\n",
    "silhouette_avg_som = silhouette_score(mySeries, som_label)\n",
    "silhouette_avg_ant = silhouette_score(mySeries, clusters_found)\n",
    "\n",
    "db_index_k = davies_bouldin_score(mySeries, labels)\n",
    "db_index_som = davies_bouldin_score(mySeries, som_label)\n",
    "db_index_ant = davies_bouldin_score(mySeries, clusters_found)\n",
    "\n",
    "new_row = pd.DataFrame({\n",
    "    'Silhouette score': silhouette_avg_ant,\n",
    "    'Davies-Bouldin Index': db_index_ant,\n",
    "}, index=[\"AntClust (DTW distance)\"])\n",
    "df = pd.concat([df, new_row])\n",
    "\n",
    "new_row = pd.DataFrame({\n",
    "    'Silhouette score': silhouette_avg_k,\n",
    "    'Davies-Bouldin Index': db_index_k,\n",
    "}, index=[f\"K means (k={cluster_count})\"])\n",
    "df = pd.concat([df, new_row])\n",
    "\n",
    "new_row = pd.DataFrame({\n",
    "    'Silhouette score': silhouette_avg_som,\n",
    "    'Davies-Bouldin Index': db_index_som,\n",
    "}, index=[\"Self Organizing Maps\"])\n",
    "df = pd.concat([df, new_row])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005716874269998784\n"
     ]
    }
   ],
   "source": [
    "print(abs(db_index_som-db_index_ant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
