{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1526fe4e-3cf5-4d61-8137-8b2c6a80e620",
   "metadata": {},
   "source": [
    "This notebook defines all functions needed to test the clustering performance of AntClust on images.\n",
    "It will expect that the images for each cluster reside in the a foldes (called \"data\") with the following structure:\n",
    "```\n",
    "data\n",
    "  folder_with_images_cluster_0\n",
    "    image_0\n",
    "    image_1\n",
    "  folder_with_images_cluster_1\n",
    "    image_0\n",
    "    image_1\n",
    "  folder_with_images_cluster_2\n",
    "    ...\n",
    "    ...\n",
    "  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d91aaea-20e7-44e4-aca4-cd8aa580ca05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "import math\n",
    "import os\n",
    "import random as rng\n",
    "import sys\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# make AntClus dir known\n",
    "import sys\n",
    "sys.path.append(\"../AntClust\")\n",
    "from AntClust import AntClust\n",
    "from distance_classes import (\n",
    "    opencv_image_flann_similarity,\n",
    "    opencv_image_orb_similarity,\n",
    "    opencv_orb_similarity,\n",
    "    precomputed_similarity_matrix\n",
    ")\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from rules import labroche_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66adadf7-426c-4d78-9fe5-edad31bc21a7",
   "metadata": {},
   "source": [
    "# data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915cc78a-8c29-4876-858a-8dbba200b44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_cluster_images_static(\n",
    "    data_folder, num_clusters, num_images_per_cluster, seed=3\n",
    "):\n",
    "    \"\"\"\n",
    "    Will generate num_clusters clusters with num_images_per_cluster pictures each\n",
    "    \"\"\"\n",
    "    # get the cars\n",
    "    car_dir_names = sorted(os.listdir(data_folder), key=lambda x: x)\n",
    "\n",
    "    # remove ipycheckpoint\n",
    "    if car_dir_names[0] == \".ipynb_checkpoints\":\n",
    "        car_dir_names = car_dir_names[1::]\n",
    "\n",
    "    # make a random shuffle of the cars/folders to take\n",
    "    rng.seed(seed)\n",
    "    cars_to_take = rng.sample(car_dir_names, len(car_dir_names))\n",
    "    cars_to_take = cars_to_take[0:num_clusters:]\n",
    "\n",
    "    # make the cluster data and the labels\n",
    "    # generate num_clusters and add num_images_per_cluster to each cluster\n",
    "    cluster_image: list = []\n",
    "    cluster_labels: list = []\n",
    "\n",
    "    label_counter = 0\n",
    "    for car_folder in cars_to_take:\n",
    "        # take images and shuffle them\n",
    "        imgs = sorted(os.listdir(data_folder + \"/\" + car_folder), key=lambda x: x)\n",
    "        imgs = rng.sample(imgs, len(imgs))\n",
    "\n",
    "        # make data and labels\n",
    "        # add the respectiv car folder as path\n",
    "        cluster_image = cluster_image + [\n",
    "            str(car_folder) + \"/\" + image for image in imgs[0:num_images_per_cluster:]\n",
    "        ]\n",
    "        cluster_labels = cluster_labels + [label_counter] * num_images_per_cluster\n",
    "        label_counter += 1\n",
    "\n",
    "    # read the images as opencv images from disk\n",
    "    image_data = []\n",
    "    for image_file in cluster_image:\n",
    "        image_data.append(\n",
    "            [cv.imread(data_folder + \"/\" + image_file, cv.IMREAD_GRAYSCALE)]\n",
    "        )\n",
    "\n",
    "    return cluster_image, image_data, cluster_labels\n",
    "\n",
    "\n",
    "def data_cluster_images_dynamic(\n",
    "    data_folder,\n",
    "    num_clusters,\n",
    "    num_images_per_cluster_min,\n",
    "    num_images_per_cluster_max,\n",
    "    seed=3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Will generate num_clusters clusters where a random ammount of images in\n",
    "    the range [num_images_per_cluster_min, num_images_per_cluster_max]\n",
    "    \"\"\"\n",
    "    # get the cars\n",
    "    car_dir_names = sorted(os.listdir(data_folder), key=lambda x: x)\n",
    "\n",
    "    # remove ipycheckpoint\n",
    "    if car_dir_names[0] == \".ipynb_checkpoints\":\n",
    "        car_dir_names = car_dir_names[1::]\n",
    "\n",
    "    # make a random shuffle of the cars/folders to take\n",
    "    rng.seed(seed)\n",
    "    cars_to_take = rng.sample(car_dir_names, len(car_dir_names))\n",
    "    cars_to_take = cars_to_take[0:num_clusters:]\n",
    "\n",
    "    # make the cluster data and the labels\n",
    "    # generate num_clusters and add a random ammount of images (in min, max range) to each cluster\n",
    "    cluster_image: list = []\n",
    "    cluster_labels: list = []\n",
    "\n",
    "    label_counter = 0\n",
    "    for car_folder in cars_to_take:\n",
    "        # take images and shuffle them\n",
    "        imgs = sorted(os.listdir(data_folder + \"/\" + car_folder), key=lambda x: x)\n",
    "        imgs = rng.sample(imgs, len(imgs))\n",
    "\n",
    "        # make data and labels\n",
    "        num_images = rng.randint(num_images_per_cluster_min, num_images_per_cluster_max)\n",
    "        # add the respectiv car folder as path\n",
    "        cluster_image = cluster_image + [\n",
    "            str(car_folder) + \"/\" + image for image in imgs[0:num_images:]\n",
    "        ]\n",
    "        cluster_labels = cluster_labels + [label_counter] * num_images\n",
    "        label_counter += 1\n",
    "\n",
    "    # read the images as opencv images from disk\n",
    "    # and put them into their own array as data tuple\n",
    "    image_data = []\n",
    "    for image_file in cluster_image:\n",
    "        image_data.append(\n",
    "            [cv.imread(data_folder + \"/\" + image_file, cv.IMREAD_GRAYSCALE)]\n",
    "        )\n",
    "\n",
    "    return cluster_image, image_data, cluster_labels\n",
    "\n",
    "\n",
    "def compute_orb_image_features(images, image_resize_size):\n",
    "    # Initiate ORB detector for feature extraction\n",
    "    orb = cv.ORB_create()\n",
    "    descriptors = []\n",
    "    # compute key points and descriptors\n",
    "    for image in images:\n",
    "        img = image[0]\n",
    "        img = cv.resize(img, image_resize_size)\n",
    "        kp, des = orb.detectAndCompute(img, None)\n",
    "        descriptors.append([des])\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514c98b-4f7a-459a-bac1-2387c90fabd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ant Clust parameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d751bfcb-7b30-4be4-92db-3709bd06b582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing params 0 out of 375\n",
      "{'alpha': 150, 'betta': 0.3, 'shrink': 0.1, 'removal': 0.1}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(params[key])\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(f\"alpha {alpha}\")\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print(f\"betta {betta}\")\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print(f\"shrink {shrink}\")\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# print(f\"removal {removal}\")\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Data generation\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# ----------------\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m image_names, images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mdata_cluster_images_static\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_clusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues_per_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m images \u001b[38;5;241m=\u001b[39m compute_orb_image_features(images, image_resize_size)\n\u001b[1;32m     56\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(images, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mdata_cluster_images_static\u001b[0;34m(data_folder, num_clusters, num_images_per_cluster, seed)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mWill generate num_clusters clusters with num_images_per_cluster pictures each\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# get the cars\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m car_dir_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# remove ipycheckpoint\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m car_dir_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "# test variables\n",
    "# --------------\n",
    "num_clusters = 30\n",
    "data_folder = \"data\"\n",
    "values_per_cluster = 18\n",
    "seed = 9\n",
    "image_resize_size = (150, 172)\n",
    "\n",
    "# parameters\n",
    "alpha_ant_meeting_iterations = [150, 200, 250, 300, 400]\n",
    "betta_template_init_meetings = [0.3, 0.5, 0.7]\n",
    "nest_shrink_prop = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "nest_removal_prop = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "params = {}\n",
    "i = 0\n",
    "for alpha in alpha_ant_meeting_iterations:\n",
    "    for betta in betta_template_init_meetings:\n",
    "        for shrink in nest_shrink_prop:\n",
    "            for removal in nest_removal_prop:\n",
    "                params[i] = {\n",
    "                    \"alpha\": alpha,\n",
    "                    \"betta\": betta,\n",
    "                    \"shrink\": shrink,\n",
    "                    \"removal\": removal,\n",
    "                }\n",
    "                i += 1\n",
    "\n",
    "\n",
    "# result arrays\n",
    "ari_antclust = []\n",
    "\n",
    "\n",
    "# test loop\n",
    "t_0 = time.time()\n",
    "i = 0\n",
    "for key in list(params.keys()):\n",
    "    alpha = params[key][\"alpha\"]\n",
    "    betta = params[key][\"betta\"]\n",
    "    shrink = params[key][\"shrink\"]\n",
    "    removal = params[key][\"removal\"]\n",
    "    t_1 = time.time()\n",
    "    print(f\"testing params {i} out of {len(list(params.keys()))}\")\n",
    "    i += 1\n",
    "    print(params[key])\n",
    "    # print(f\"alpha {alpha}\")\n",
    "    # print(f\"betta {betta}\")\n",
    "    # print(f\"shrink {shrink}\")\n",
    "    # print(f\"removal {removal}\")\n",
    "    # Data generation\n",
    "    # ----------------\n",
    "    image_names, images, labels = data_cluster_images_static(\n",
    "        data_folder, num_clusters, values_per_cluster, seed\n",
    "    )\n",
    "    images = compute_orb_image_features(images, image_resize_size)\n",
    "    data = np.array(images, dtype=list)\n",
    "    labels = np.array(labels)\n",
    "    # AntClust\n",
    "    # ----------\n",
    "    # similarity function\n",
    "    f_sim = [opencv_descriptor_flann_similarity(max_distance=70)]\n",
    "    # rules\n",
    "    rules = labroche_rules()\n",
    "    # AntClust\n",
    "    ant_clust = AntClust(\n",
    "        f_sim,\n",
    "        rules,\n",
    "        alpha_ant_meeting_iterations=alpha,\n",
    "        betta_template_init_meetings=betta,\n",
    "        nest_shrink_prop=shrink,\n",
    "        nest_removal_prop=removal,\n",
    "        print_status=False,\n",
    "    )\n",
    "    # find clusters\n",
    "    ant_clust.fit(data)\n",
    "    # get the clustering result\n",
    "    y_pred = ant_clust.get_clusters()\n",
    "    # calculate the ari score\n",
    "    ari_score = adjusted_rand_score(labels, y_pred)\n",
    "    # append score\n",
    "    ari_antclust.append(ari_score)\n",
    "    # print test time\n",
    "    print(f\"testing took {time.time()-t_1} seconds\")\n",
    "    print()\n",
    "\n",
    "print(f\"testing took {time.time() - t_0} seconds\")\n",
    "\n",
    "# saving best params\n",
    "print(f' min ari score {min(ari_antclust)}')\n",
    "print(f' max ari score {max(ari_antclust)}')\n",
    "\n",
    "params_best_key = np.where(np.array(ari_antclust) == max(ari_antclust))[0][0]\n",
    "ant_clust_params = params[params_best_key]\n",
    "\n",
    "print('best params')\n",
    "print(ant_clust_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_evolution",
   "language": "python",
   "name": "venv_evolution"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
