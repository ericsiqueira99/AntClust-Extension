{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77308a2e-1a85-4c55-8dd6-aa3f0de0a8c2",
   "metadata": {},
   "source": [
    "Todos:\n",
    "* generate test data set\n",
    "    - number of clusters\n",
    "    - space between clusters (from this the max pivot deviation is calculated)\n",
    "    - values per cluster (also random range possible, then the start and end e.g. 10-42 should be possible -make adapted function for this- )\n",
    "* is the above okay since it is a unique distribution and cluster centers might vary... in the beginning yes, it is one of many tests and this one tests specifically how ant clust performs on many uniformly distributed clusters. \n",
    "\n",
    "Idea:\n",
    "* make function that generates the set\n",
    "* each cluster has a pivot element from which single data points deviate.\n",
    "* the pivot is a unique cluster id (no need to label the clusters)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18887807-551d-4471-a166-6c9818ade73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make AntClus dir known\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../AntClust\")\n",
    "\n",
    "# generally used\n",
    "import random as rng\n",
    "\n",
    "import numpy as np\n",
    "from AntClust import AntClust\n",
    "\n",
    "# AntClust\n",
    "from distance_classes import similarity_1d\n",
    "from rules import labroche_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b9b8c3-de64-4fb5-85a2-5828832effe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uniform_cluster_data_random(\n",
    "    num_clusters,\n",
    "    cluster_width,\n",
    "    values_per_cluster_min=0,\n",
    "    values_per_cluster_max=100,\n",
    "    rng_seed=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Makes a series of numbers that can be clustered together.\n",
    "    Each cluster is getting a pivot element, starting by one and counts to\n",
    "    num_clusters. From this a random deviation is generated which will be\n",
    "    the new data point. If the deviation is to larg there will be a string\n",
    "    of numbers with no space in between and as such no clusters.\n",
    "    cluster_width: how far can the data point be from its pivot,\n",
    "    only values <0.25 makes sense.\n",
    "    \"\"\"\n",
    "    # variables\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    rng.seed(rng_seed)\n",
    "    rand_min = -cluster_width\n",
    "    rand_max = cluster_width\n",
    "    rand_range = rand_max - rand_min\n",
    "\n",
    "    # make data for each cluster pivot\n",
    "    for c_pivot in range(1, num_clusters + 1):\n",
    "        c_data = []\n",
    "        c_labels = []\n",
    "\n",
    "        # how many values to generate?\n",
    "        values_per_cluster = rng.randin(values_per_cluster_min, values_per_cluster_max)\n",
    "        # generate data points\n",
    "        for n in range(0, values_per_cluster):\n",
    "            # calc pivot deviation and add it\n",
    "            dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # check if exist and if create new\n",
    "            while dp in c_data:\n",
    "                dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # add it with the labe to the cluster data\n",
    "            c_data.append(dp)\n",
    "            c_labels.append(c_pivot - 1)\n",
    "\n",
    "        # add the cluster data to overall data\n",
    "        data = data + c_data\n",
    "        labels = labels + c_labels\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def uniform_cluster_data(num_clusters, cluster_width, values_per_cluster, rng_seed=1):\n",
    "    \"\"\"\n",
    "    Makes a series of numbers that can be clustered together.\n",
    "    Each cluster is getting a pivot element, starting by one and counts to\n",
    "    num_clusters. From this a random deviation is generated which will be\n",
    "    the new data point. If the deviation is to larg there will be a string\n",
    "    of numbers with no space in between and as such no clusters.\n",
    "    cluster_width: how far can the data point be from its pivot,\n",
    "    only values <0.25 makes sense.\n",
    "    \"\"\"\n",
    "    # variables\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    rng.seed(rng_seed)\n",
    "    rand_min = -cluster_width\n",
    "    rand_max = cluster_width\n",
    "    rand_range = rand_max - rand_min\n",
    "\n",
    "    # make data for each cluster pivot\n",
    "    for c_pivot in range(1, num_clusters + 1):\n",
    "        c_data = []\n",
    "        c_labels = []\n",
    "\n",
    "        # generate data points\n",
    "        for n in range(0, values_per_cluster):\n",
    "            # calc pivot deviation and add it\n",
    "            dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # check if exist and if create new\n",
    "            while dp in c_data:\n",
    "                dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # add it with the labe to the cluster data\n",
    "            c_data.append(dp)\n",
    "            c_labels.append(c_pivot - 1)\n",
    "\n",
    "        # add the cluster data to overall data\n",
    "        data = data + c_data\n",
    "        labels = labels + c_labels\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def make_cluster_mask(clust_labels):\n",
    "    \"\"\"\n",
    "    This function will make a cluster mask which will\n",
    "    hold the start and end index from each cluster.\n",
    "    \"\"\"\n",
    "    clust_mask = []\n",
    "    # get current clust\n",
    "    current_clust_label = clust_labels[0]\n",
    "    current_clust_start = 0\n",
    "\n",
    "    # loop through all clusts\n",
    "    for i in range(len(clust_labels)):\n",
    "        if clust_labels[i] != current_clust_label:\n",
    "            clust_mask.append([current_clust_start, i - 1])\n",
    "            current_clust_label = clust_labels[i]\n",
    "            current_clust_start = i\n",
    "    # append the final mask\n",
    "    clust_mask.append([current_clust_start, i])\n",
    "\n",
    "    return clust_mask\n",
    "\n",
    "\n",
    "def error_cluster_mask(cluster_result, cluster_mask, print_error_per_cluster=False):\n",
    "    \"\"\"\n",
    "    Will test the cluster error based on the cluster mask approach.\n",
    "    For every cluster in the mask it is checked how many clusters where found\n",
    "    in the respective area. It is determined based on the highest representation\n",
    "    number how many how many missclassified data points exist.\n",
    "    It is assumed that the cluster labels are ascendendly ordered and no number\n",
    "    in that row is missing, e.g.:\n",
    "    correct : [0,0,0,0,1,1,1,2,2,...]\n",
    "    false   : [0,0,0,3,3,2,2,....]\n",
    "    \"\"\"\n",
    "    # vars\n",
    "    cluster_errors = []\n",
    "    already_used_labels = []\n",
    "\n",
    "    # find the most significant number inside the clust range\n",
    "    for c_range in cluster_mask:\n",
    "        label_dict = {}\n",
    "\n",
    "        # count numbers inside the cluster range\n",
    "        for i in range(c_range[0], c_range[1] + 1):\n",
    "            if cluster_result[i] not in label_dict:\n",
    "                label_dict[cluster_result[i]] = 1\n",
    "            else:\n",
    "                label_dict[cluster_result[i]] += 1\n",
    "        # find most dominant one, going to assumt this is the cluster label.\n",
    "        # If two labels are equally dominant use the first occured\n",
    "        max_index = np.where(\n",
    "            list(label_dict.values()) == np.max(list(label_dict.values()))\n",
    "        )[0][0]\n",
    "        max_key = list(label_dict.keys())[max_index]\n",
    "\n",
    "        # save nums with key and occurence and clust range index\n",
    "        # count highest\n",
    "        # if used check the occurences\n",
    "        # if occurence here more then reassign and remove from the old one\n",
    "        #     and find a new one for the old one by counting and us one that es not already used\n",
    "        #     If no is found assign no cluster label\n",
    "        # else (occurence less) go through all others until found one that is not used\n",
    "        #     if all are used assign no label\n",
    "        # save the labels in a list where [clust_range, label]\n",
    "        # then you can go throug that list and count the errors (full error if label -1)\n",
    "\n",
    "        # count for errors\n",
    "        # now check how many of the same label are inside the cluster which tells\n",
    "        # the ones that are correctly clustered.\n",
    "        num_correct = 0\n",
    "        for i in range(c_range[0], c_range[1] + 1):\n",
    "            if cluster_result[i] == max_key:\n",
    "                num_correct += 1\n",
    "\n",
    "        # calc and append error\n",
    "        cluster_errors.append(1 - (num_correct / (c_range[1] - c_range[0] + 1)))\n",
    "\n",
    "    # return overall error\n",
    "    if print_error_per_cluster:\n",
    "        print(cluster_errors)\n",
    "    return sum(cluster_errors) / len(cluster_errors)\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# - run with different seeds and take the mean error\n",
    "def run_benchmark():\n",
    "    # generate two for loops that generate the data and then run antclust\n",
    "    # and save the error to a 2d list of lists\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf76fde-75d3-4f8e-9114-c7ca5f0e5eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 99], [100, 199], [200, 299], [300, 399], [400, 499]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "# data\n",
    "# ------------------\n",
    "num_clusters = 5\n",
    "cluster_width = 0.1  # this defines how hard the clustering task is?\n",
    "values_per_cluster = 100\n",
    "data, labels = uniform_cluster_data(\n",
    "    num_clusters, cluster_width, values_per_cluster, rng_seed=3\n",
    ")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "cluster_mask = make_cluster_mask(labels)\n",
    "error_cluster_mask(labels, cluster_mask)\n",
    "cluster_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb37ac7-31b4-490c-a12c-b3303c709b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntClust: phase 1 of 3 -> meeting ants\n",
      "left meetings  22500 / 22500\n",
      "left meetings  20250 / 22500\n",
      "left meetings  18000 / 22500\n",
      "left meetings  15750 / 22500\n",
      "left meetings  13500 / 22500\n",
      "left meetings  11250 / 22500\n",
      "left meetings  9000 / 22500\n",
      "left meetings  6750 / 22500\n",
      "left meetings  4500 / 22500\n",
      "left meetings  2250 / 22500\n",
      "AntClust: phase 2 of 3 -> shrink nests\n",
      "AntClust: phase 3 of 3 -> reassign ants\n",
      "label error: 0.9666666666666667\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999998, 0.4, 0.4, 0.4, 0.6, 0.4, 0.6, 0.5, 0.0, 0.0, 0.09999999999999998, 0.0, 0.0, 0.4, 0.5, 0.19999999999999996, 0.19999999999999996, 0.09999999999999998, 0.09999999999999998, 0.0, 0.0]\n",
      "cluster mask error: 0.16666666666666666\n",
      "clusters found ids \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "# data\n",
    "# ------------------\n",
    "num_clusters = 30\n",
    "cluster_width = 0.1  # this defines how hard the clustering task is?\n",
    "values_per_cluster = 10\n",
    "data, labels = uniform_cluster_data(\n",
    "    num_clusters, cluster_width, values_per_cluster, rng_seed=3\n",
    ")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# ------------------\n",
    "# AntClust\n",
    "# ------------------\n",
    "# similarity function\n",
    "f_sim = [similarity_1d(data.min(), data.max())]\n",
    "\n",
    "# rules\n",
    "rules = labroche_rules()\n",
    "\n",
    "# AntClust\n",
    "ant_clust = AntClust(data, f_sim, rules, alpha_ant_meeting_iterations=150)\n",
    "\n",
    "# find clusters\n",
    "ant_clust.find_clusters()\n",
    "\n",
    "# get the clustering result\n",
    "clusters_found = ant_clust.get_clusters()\n",
    "\n",
    "# ------------------\n",
    "# performance\n",
    "# ------------------\n",
    "# how many labels differ?\n",
    "num_missclassified = len(np.where(clusters_found != labels)[0])\n",
    "error = num_missclassified / len(data)\n",
    "print(f\"label error: {error}\")\n",
    "\n",
    "# error with cluster mask approach\n",
    "cluster_mask = make_cluster_mask(labels)\n",
    "error = error_cluster_mask(clusters_found, cluster_mask, print_error_per_cluster=True)\n",
    "print(f\"cluster mask error: {error}\")\n",
    "\n",
    "# labels found\n",
    "print(f\"clusters found ids \\n\")\n",
    "clusters_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0b21146-7dc9-44b8-ac69-69d6915936e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a339113-343c-493d-99e5-5a2a28b97693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345ed0a-e7c6-4580-8eb4-41a1af0f4d80",
   "metadata": {},
   "source": [
    "# scikit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9816df5-974f-4328-8906-7bb15efbc67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b5cf4a-8ed3-4c72-bb95-8626aefb46e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78019b02-9695-4fcf-b1c2-6734a3b8ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472017837235229\n",
      "0.10545372984668971\n",
      "1.0815245607018105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    davies_bouldin_score,\n",
    "    mutual_info_score,\n",
    "    rand_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "# RI = (number of agreeing pairs) / (number of pairs)\n",
    "ris = rand_score(labels, clusters_found)\n",
    "print(ris)\n",
    "\n",
    "# ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n",
    "ari = adjusted_rand_score(labels, clusters_found)\n",
    "print(ari)\n",
    "\n",
    "#\n",
    "# ss = silhouette_score(labels, clusters_found)\n",
    "\n",
    "# print(ss)\n",
    "\n",
    "\n",
    "#\n",
    "# dbs = davies_bouldin_score(labels, clusters_found)\n",
    "# print(dbs)\n",
    "\n",
    "\n",
    "mis = mutual_info_score(labels, clusters_found)\n",
    "print(mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f7d19-c0f8-4583-94bf-0669d78818bd",
   "metadata": {},
   "source": [
    "# cluster performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7acfcd09-8eaf-4534-8225-a9b1c599d480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "def run_cluster_test_static(\n",
    "    clusters_min, clusters_max, values_min, values_max, cluster_width, seed=3\n",
    "):\n",
    "    # variables\n",
    "    test_fitness = []\n",
    "\n",
    "    # run all tests\n",
    "    for num_clusters in range(clusters_min, clusters_max + 1):\n",
    "        c_fitness = []\n",
    "        print(f'testing values for {num_clusters} clusters')\n",
    "        for values_per_cluster in range(values_min, values_max + 1):\n",
    "            # ------------------\n",
    "            # data\n",
    "            # ------------------\n",
    "            data, labels = uniform_cluster_data(\n",
    "                num_clusters, cluster_width, values_per_cluster, seed\n",
    "            )\n",
    "            data = np.array(data)\n",
    "            labels = np.array(labels)\n",
    "\n",
    "            # ------------------\n",
    "            # run clustering\n",
    "            # ------------------\n",
    "            # similarity function\n",
    "            f_sim = [similarity_1d(data.min(), data.max())]\n",
    "\n",
    "            # rules\n",
    "            rules = labroche_rules()\n",
    "\n",
    "            # AntClust\n",
    "            ant_clust = AntClust(data, f_sim, rules, alpha_ant_meeting_iterations=150, print_status=False)\n",
    "\n",
    "            # find clusters\n",
    "            ant_clust.find_clusters()\n",
    "\n",
    "            # get the clustering result\n",
    "            clusters_found = ant_clust.get_clusters()\n",
    "\n",
    "            # ------------------\n",
    "            # calc error\n",
    "            # ------------------\n",
    "            # use ari as score\n",
    "            ari = adjusted_rand_score(labels, clusters_found)\n",
    "            c_fitness.append(ari)\n",
    "\n",
    "        # append fitness for that cluster ammount\n",
    "        test_fitness.append(c_fitness)\n",
    "\n",
    "    # finally\n",
    "    return test_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3afe12bc-7699-4948-87eb-d2e1cdc6e670",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing values for 2 clusters\n",
      "testing values for 3 clusters\n",
      "testing values for 4 clusters\n",
      "testing values for 5 clusters\n",
      "testing values for 6 clusters\n",
      "testing values for 7 clusters\n",
      "testing values for 8 clusters\n",
      "testing values for 9 clusters\n",
      "testing values for 10 clusters\n",
      "testing values for 11 clusters\n",
      "testing values for 12 clusters\n",
      "testing values for 13 clusters\n",
      "testing values for 14 clusters\n",
      "testing values for 15 clusters\n",
      "testing values for 16 clusters\n",
      "testing values for 17 clusters\n",
      "testing values for 18 clusters\n",
      "testing values for 19 clusters\n",
      "testing values for 20 clusters\n",
      "testing values for 21 clusters\n",
      "testing values for 22 clusters\n",
      "testing values for 23 clusters\n",
      "testing values for 24 clusters\n",
      "testing values for 25 clusters\n",
      "testing values for 26 clusters\n",
      "testing values for 27 clusters\n",
      "testing values for 28 clusters\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1479/2614302391.py\", line 11, in <module>\n",
      "    test_data = run_cluster_test_static(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_1479/584531745.py\", line 37, in run_cluster_test_static\n",
      "    ant_clust.find_clusters()\n",
      "  File \"/home/juppy/hostshared/ant_clust_perf/antclust/tests/../AntClust/AntClust.py\", line 389, in find_clusters\n",
      "    self.__reassign()\n",
      "  File \"/home/juppy/hostshared/ant_clust_perf/antclust/tests/../AntClust/AntClust.py\", line -1, in __reassign\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/juppy/venv_evolution/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# ------------------\n",
    "# test\n",
    "# ------------------\n",
    "clusters_min = 2\n",
    "clusters_max = 30\n",
    "values_min = 2\n",
    "values_max = 100\n",
    "cluster_width = 0.1  # this defines how hard the clustering task is?\n",
    "seed = 3\n",
    "\n",
    "test_data = run_cluster_test_static(\n",
    "    clusters_min, clusters_max, values_min, values_max, cluster_width, seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0c1a0c-3b18-476f-a942-482be57899db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edd47f6-9b78-42a7-92bd-11d66dad3d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.arange(clusters_min, clusters_max+1, 1)\n",
    "#X = X[::-1]\n",
    "Y = np.arange(values_min, values_max+1, 1)\n",
    "#Y = Y[::-1]\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z = np.array(test_data).transpose()\n",
    "#Z = Z[::-1]\n",
    "print(X)\n",
    "print(Y)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483b0b1-6eef-475d-a247-e163838f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9de419-2aa5-4e85-979a-16268e31db1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "#X = np.arange(clusters_min, clusters_max, 1)\n",
    "#Y = np.arange(values_min, values_max, 1)\n",
    "#X, Y = np.meshgrid(X, Y)\n",
    "#Z = np.array(test_data)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.spring,\n",
    "                       linewidth=0, antialiased=True)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1.0, 1.0)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# A StrMethodFormatter is used automatically\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# set axis labels\n",
    "plt.xlabel('clusters')\n",
    "plt.ylabel('datapoints')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbc4f33-28e7-4d07-bf97-443b2b7e7885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01ea951-2977-4a3c-ba89-8eb7c2a63684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=True)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1.01, 1.01)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# A StrMethodFormatter is used automatically\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a07aa-2b35-41f9-a2e5-5878a9f1f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1,1],[1,1]]\n",
    "Y = [[1,1],[1,1]]\n",
    "Z = [[1,1],[1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa853dd-218b-43b8-b4c6-1b29eb3a5194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=True)\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_zlim(-1.01, 1.01)\n",
    "ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# A StrMethodFormatter is used automatically\n",
    "ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d688295-64d4-4d69-a686-195a35454936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make data\n",
    "X = np.arange(-5, 5, 0.25)\n",
    "Y = np.arange(-5, 5, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X**2 + Y**2)\n",
    "Z = np.sin(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337afe17-054f-4cfe-bab0-840bc05c940d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dbd16c-b9c2-4d17-bfe0-54c289fb90f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_evolution",
   "language": "python",
   "name": "venv_evolution"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
