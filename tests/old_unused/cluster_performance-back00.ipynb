{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77308a2e-1a85-4c55-8dd6-aa3f0de0a8c2",
   "metadata": {},
   "source": [
    "Todos:\n",
    "* generate test data set\n",
    "    - number of clusters\n",
    "    - space between clusters (from this the max pivot deviation is calculated)\n",
    "    - values per cluster (also random range possible, then the start and end e.g. 10-42 should be possible -make adapted function for this- )\n",
    "* is the above okay since it is a unique distribution and cluster centers might vary... in the beginning yes, it is one of many tests and this one tests specifically how ant clust performs on many uniformly distributed clusters. \n",
    "\n",
    "Idea:\n",
    "* make function that generates the set\n",
    "* each cluster has a pivot element from which single data points deviate.\n",
    "* the pivot is a unique cluster id (no need to label the clusters)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18887807-551d-4471-a166-6c9818ade73b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make AntClus dir known\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../AntClust\")\n",
    "\n",
    "# generally used\n",
    "import random as rng\n",
    "\n",
    "import numpy as np\n",
    "from AntClust import AntClust\n",
    "\n",
    "# AntClust\n",
    "from distance_classes import similarity_1d\n",
    "from rules import labroche_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b9b8c3-de64-4fb5-85a2-5828832effe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def uniform_cluster_data_random(\n",
    "    num_clusters,\n",
    "    cluster_width,\n",
    "    values_per_cluster_min=0,\n",
    "    values_per_cluster_max=100,\n",
    "    rng_seed=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Makes a series of numbers that can be clustered together.\n",
    "    Each cluster is getting a pivot element, starting by one and counts to\n",
    "    num_clusters. From this a random deviation is generated which will be\n",
    "    the new data point. If the deviation is to larg there will be a string\n",
    "    of numbers with no space in between and as such no clusters.\n",
    "    cluster_width: how far can the data point be from its pivot,\n",
    "    only values <0.25 makes sense.\n",
    "    \"\"\"\n",
    "    # variables\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    rng.seed(rng_seed)\n",
    "    rand_min = -cluster_width\n",
    "    rand_max = cluster_width\n",
    "    rand_range = rand_max - rand_min\n",
    "\n",
    "    # make data for each cluster pivot\n",
    "    for c_pivot in range(1, num_clusters + 1):\n",
    "        c_data = []\n",
    "        c_labels = []\n",
    "\n",
    "        # how many values to generate?\n",
    "        values_per_cluster = rng.randin(values_per_cluster_min, values_per_cluster_max)\n",
    "        # generate data points\n",
    "        for n in range(0, values_per_cluster):\n",
    "            # calc pivot deviation and add it\n",
    "            dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # check if exist and if create new\n",
    "            while dp in c_data:\n",
    "                dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # add it with the labe to the cluster data\n",
    "            c_data.append(dp)\n",
    "            c_labels.append(c_pivot - 1)\n",
    "\n",
    "        # add the cluster data to overall data\n",
    "        data = data + c_data\n",
    "        labels = labels + c_labels\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def uniform_cluster_data(num_clusters, cluster_width, values_per_cluster, rng_seed=1):\n",
    "    \"\"\"\n",
    "    Makes a series of numbers that can be clustered together.\n",
    "    Each cluster is getting a pivot element, starting by one and counts to\n",
    "    num_clusters. From this a random deviation is generated which will be\n",
    "    the new data point. If the deviation is to larg there will be a string\n",
    "    of numbers with no space in between and as such no clusters.\n",
    "    cluster_width: how far can the data point be from its pivot,\n",
    "    only values <0.25 makes sense.\n",
    "    \"\"\"\n",
    "    # variables\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    rng.seed(rng_seed)\n",
    "    rand_min = -cluster_width\n",
    "    rand_max = cluster_width\n",
    "    rand_range = rand_max - rand_min\n",
    "\n",
    "    # make data for each cluster pivot\n",
    "    for c_pivot in range(1, num_clusters + 1):\n",
    "        c_data = []\n",
    "        c_labels = []\n",
    "\n",
    "        # generate data points\n",
    "        for n in range(0, values_per_cluster):\n",
    "            # calc pivot deviation and add it\n",
    "            dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # check if exist and if create new\n",
    "            while dp in c_data:\n",
    "                dp = [c_pivot + (rand_min + rng.random() * rand_range)]\n",
    "\n",
    "            # add it with the labe to the cluster data\n",
    "            c_data.append(dp)\n",
    "            c_labels.append(c_pivot - 1)\n",
    "\n",
    "        # add the cluster data to overall data\n",
    "        data = data + c_data\n",
    "        labels = labels + c_labels\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def make_cluster_mask(clust_labels):\n",
    "    \"\"\"\n",
    "    This function will make a cluster mask which will\n",
    "    hold the start and end index from each cluster.\n",
    "    \"\"\"\n",
    "    clust_mask = []\n",
    "    # get current clust\n",
    "    current_clust_label = clust_labels[0]\n",
    "    current_clust_start = 0\n",
    "\n",
    "    # loop through all clusts\n",
    "    for i in range(len(clust_labels)):\n",
    "        if clust_labels[i] != current_clust_label:\n",
    "            clust_mask.append([current_clust_start, i - 1])\n",
    "            current_clust_label = clust_labels[i]\n",
    "            current_clust_start = i\n",
    "    # append the final mask\n",
    "    clust_mask.append([current_clust_start, i])\n",
    "    \n",
    "    return clust_mask\n",
    "\n",
    "\n",
    "def error_cluster_mask(cluster_result, cluster_mask, print_error_per_cluster=False):\n",
    "    \"\"\"\n",
    "    Will test the cluster error based on the cluster mask approach.\n",
    "    For every cluster in the mask it is checked how many clusters where found\n",
    "    in the respective area. It is determined based on the highest representation\n",
    "    number how many how many missclassified data points exist.\n",
    "    It is assumed that the cluster labels are ascendendly ordered and no number\n",
    "    in that row is missing, e.g.:\n",
    "    correct : [0,0,0,0,1,1,1,2,2,...]\n",
    "    false   : [0,0,0,3,3,2,2,....]\n",
    "    \"\"\"\n",
    "    # vars\n",
    "    cluster_errors = []\n",
    "    already_used_labels = []\n",
    "\n",
    "    # find the most significant number inside the clust range\n",
    "    for c_range in cluster_mask:\n",
    "        label_dict = {}\n",
    "\n",
    "        # count numbers inside the cluster range\n",
    "        for i in range(c_range[0], c_range[1] + 1):\n",
    "            if cluster_result[i] not in label_dict:\n",
    "                label_dict[cluster_result[i]] = 1\n",
    "            else:\n",
    "                label_dict[cluster_result[i]] += 1\n",
    "        # find most dominant one, going to assumt this is the cluster label.\n",
    "        # If two labels are equally dominant use the first occured\n",
    "        max_index = np.where(\n",
    "            list(label_dict.values()) == np.max(list(label_dict.values()))\n",
    "        )[0][0]\n",
    "        max_key = list(label_dict.keys())[max_index]\n",
    "        \n",
    "        # save nums with key and occurence and clust range index\n",
    "        # count highest\n",
    "        # if used check the occurences\n",
    "        # if occurence here more then reassign and remove from the old one \n",
    "        #     and find a new one for the old one by counting and us one that es not already used\n",
    "        #     If no is found assign no cluster label\n",
    "        # else (occurence less) go through all others until found one that is not used\n",
    "        #     if all are used assign no label\n",
    "        # save the labels in a list where [clust_range, label]\n",
    "        # then you can go throug that list and count the errors (full error if label -1)\n",
    "\n",
    "        # count for errors\n",
    "        # now check how many of the same label are inside the cluster which tells\n",
    "        # the ones that are correctly clustered.\n",
    "        num_correct = 0\n",
    "        for i in range(c_range[0], c_range[1] + 1):\n",
    "            if cluster_result[i] == max_key:\n",
    "                num_correct += 1\n",
    "\n",
    "        # calc and append error\n",
    "        cluster_errors.append(1 - (num_correct / (c_range[1] - c_range[0] + 1)))\n",
    "\n",
    "    # return overall error\n",
    "    if print_error_per_cluster:\n",
    "        print(cluster_errors)\n",
    "    return sum(cluster_errors) / len(cluster_errors)\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# - run with different seeds and take the mean error\n",
    "def run_benchmark():\n",
    "    # generate two for loops that generate the data and then run antclust\n",
    "    # and save the error to a 2d list of lists\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faf76fde-75d3-4f8e-9114-c7ca5f0e5eb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 99], [100, 199], [200, 299], [300, 399], [400, 499]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "# data\n",
    "# ------------------\n",
    "num_clusters = 5\n",
    "cluster_width = 0.1  # this defines how hard the clustering task is?\n",
    "values_per_cluster = 100\n",
    "data, labels = uniform_cluster_data(\n",
    "    num_clusters, cluster_width, values_per_cluster, rng_seed=3\n",
    ")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "cluster_mask = make_cluster_mask(labels)\n",
    "error_cluster_mask(labels, cluster_mask)\n",
    "cluster_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecb37ac7-31b4-490c-a12c-b3303c709b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AntClust: phase 1 of 3 -> meeting ants\n",
      "left meetings  22500 / 22500\n",
      "left meetings  20250 / 22500\n",
      "left meetings  18000 / 22500\n",
      "left meetings  15750 / 22500\n",
      "left meetings  13500 / 22500\n",
      "left meetings  11250 / 22500\n",
      "left meetings  9000 / 22500\n",
      "left meetings  6750 / 22500\n",
      "left meetings  4500 / 22500\n",
      "left meetings  2250 / 22500\n",
      "AntClust: phase 2 of 3 -> shrink nests\n",
      "AntClust: phase 3 of 3 -> reassign ants\n",
      "label error: 0.9666666666666667\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999998, 0.4, 0.4, 0.4, 0.6, 0.4, 0.6, 0.5, 0.0, 0.0, 0.09999999999999998, 0.0, 0.0, 0.4, 0.5, 0.19999999999999996, 0.19999999999999996, 0.09999999999999998, 0.09999999999999998, 0.0, 0.0]\n",
      "cluster mask error: 0.16666666666666666\n",
      "clusters found ids \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------\n",
    "# data\n",
    "# ------------------\n",
    "num_clusters = 30\n",
    "cluster_width = 0.1  # this defines how hard the clustering task is?\n",
    "values_per_cluster = 10\n",
    "data, labels = uniform_cluster_data(\n",
    "    num_clusters, cluster_width, values_per_cluster, rng_seed=3\n",
    ")\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# ------------------\n",
    "# AntClust\n",
    "# ------------------\n",
    "# similarity function\n",
    "f_sim = [similarity_1d(data.min(), data.max())]\n",
    "\n",
    "# rules\n",
    "rules = labroche_rules()\n",
    "\n",
    "# AntClust\n",
    "ant_clust = AntClust(data, f_sim, rules, alpha_ant_meeting_iterations=150)\n",
    "\n",
    "# find clusters\n",
    "ant_clust.find_clusters()\n",
    "\n",
    "# get the clustering result\n",
    "clusters_found = ant_clust.get_clusters()\n",
    "\n",
    "# ------------------\n",
    "# performance\n",
    "# ------------------\n",
    "# how many labels differ?\n",
    "num_missclassified = len(np.where(clusters_found != labels)[0])\n",
    "error = num_missclassified / len(data)\n",
    "print(f\"label error: {error}\")\n",
    "\n",
    "# error with cluster mask approach\n",
    "cluster_mask = make_cluster_mask(labels)\n",
    "error = error_cluster_mask(clusters_found, cluster_mask, print_error_per_cluster=True)\n",
    "print(f'cluster mask error: {error}')\n",
    "\n",
    "# labels found\n",
    "print(f'clusters found ids \\n')\n",
    "clusters_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0b21146-7dc9-44b8-ac69-69d6915936e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a339113-343c-493d-99e5-5a2a28b97693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345ed0a-e7c6-4580-8eb4-41a1af0f4d80",
   "metadata": {},
   "source": [
    "# scikit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9816df5-974f-4328-8906-7bb15efbc67c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15,\n",
       "       15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
       "       18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 20, 20, 20, 20,\n",
       "       20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 22,\n",
       "       22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "       23, 23, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25, 25, 25, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 27, 27,\n",
       "       27, 27, 27, 27, 27, 27, 27, 27, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
       "       28, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47b5cf4a-8ed3-4c72-bb95-8626aefb46e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 2, 0, 1, 1, 1, 1, 3, 1, 3, 4, 1, 1, 1, 1, 4, 1, 0,\n",
       "       1, 0, 3, 3, 3, 1, 0, 1, 1, 1, 4, 1, 4, 1, 1, 4, 1, 3, 3, 1, 4, 4,\n",
       "       3, 4, 3, 1, 4, 3, 1, 3, 3, 3, 3, 4, 1, 1, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       5, 5, 3, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 5, 5, 5, 3, 3, 3,\n",
       "       3, 3, 5, 5, 3, 3, 3, 3, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78019b02-9695-4fcf-b1c2-6734a3b8ef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472017837235229\n",
      "0.10545372984668971\n",
      "1.0815245607018105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import rand_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "# RI = (number of agreeing pairs) / (number of pairs)\n",
    "ris = rand_score(labels, clusters_found)\n",
    "print(ris)\n",
    "\n",
    "# ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n",
    "ari = adjusted_rand_score(labels, clusters_found)\n",
    "print(ari)\n",
    "\n",
    "# \n",
    "#ss = silhouette_score(labels, clusters_found)\n",
    "\n",
    "#print(ss)\n",
    "\n",
    "\n",
    "# \n",
    "#dbs = davies_bouldin_score(labels, clusters_found)\n",
    "#print(dbs)\n",
    "\n",
    "\n",
    "  \n",
    "mis = mutual_info_score(labels, clusters_found)\n",
    "print(mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17d37a-4cb7-44f3-bf49-4980933a0173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e4e038-ab1c-466c-9124-b015fb4a39c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1889291-69d5-4fab-940e-a087f77bce35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9eb3d0-1d4a-46bf-b255-e7984a6f0edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cluster_mask(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04676225-00ee-4f9a-9302-3f550c156093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32b6ef-9f83-4632-a9c9-954234db15fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496c79c-f9fe-4b20-96a7-5361010b7e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5ef76-e62f-4b51-8363-f0d4d1e3faf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37f521-b1c0-4531-8247-82346005eb87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = [[1], [2]]\n",
    "[1] in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebfc0b-a10b-46e7-8bb8-10dd2d090d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8721111-c51c-4bbf-a985-af0b1630dd8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57117078-eac2-4549-b884-d5a5c4ac5f70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min = -0.25\n",
    "max = 0.25\n",
    "\n",
    "r = max - min\n",
    "\n",
    "\n",
    "min + rng.random() * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544d64d-f102-4856-a2c4-79d4ddcb040a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min = 0.25\n",
    "max = 0.5\n",
    "\n",
    "r = max - min\n",
    "\n",
    "min + 0.99999 * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda22536-a8e5-4611-8173-cc26dfced5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af14719-407f-4e2f-896c-eae305ae11ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng.randint(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b32957-7410-4944-8e54-b82385e8f38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79718e70-63cf-4bd7-aa99-98ab03a88875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "0.9999 * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533021b-e27a-4722-95a3-a4820273dacd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_evolution",
   "language": "python",
   "name": "venv_evolution"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
