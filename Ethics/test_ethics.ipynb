{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Ethical Decision of Simple words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Ethic_Ant\n",
    "import Ethic_AntClust\n",
    "import Ethic_rules\n",
    "from afinn import Afinn\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "reload(Ethic_Ant)\n",
    "reload(Ethic_AntClust)\n",
    "reload(Ethic_rules)\n",
    "\n",
    "# Initialize AFINN\n",
    "afinn = Afinn()\n",
    "\n",
    "def normalize_list(input_list):\n",
    "    # Find the minimum and maximum values in the list\n",
    "    min_val = min(input_list)\n",
    "    max_val = max(input_list)\n",
    "    \n",
    "    # Normalize each value in the list\n",
    "    normalized_list = [(x - min_val) / (max_val - min_val) for x in input_list]\n",
    "    \n",
    "    return normalized_list\n",
    "\n",
    "# Example text\n",
    "tokens = [\"kill\", \"hurt\", \"steal\", \"lie\", \"hug\", \"love\", \"help\"]\n",
    "\n",
    "\n",
    "# Sentiment analysis and encoding\n",
    "sentiment_scores = [afinn.score(token) for token in tokens]\n",
    "sentiment_scores = normalize_list(sentiment_scores)\n",
    "\n",
    "# Example sentiment scores for tokens\n",
    "sentiment_scores_dict = dict(zip(tokens, sentiment_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ant\n",
    "def run_antclust(pop_size,sentiment_scores_dict):\n",
    "    # AntClust\n",
    "    result = {}\n",
    "    ant_clust_params={\"alpha\": 250, \"betta\": 0.5, \"shrink\": 0.2, \"removal\": 0.3}\n",
    "    ant_clust = Ethic_AntClust.AntClust(\n",
    "        pop_size,\n",
    "        Ethic_rules.ethical_rules(),\n",
    "        alpha_ant_meeting_iterations=ant_clust_params[\"alpha\"],\n",
    "        betta_template_init_meetings=ant_clust_params[\"betta\"],\n",
    "        nest_shrink_prop=ant_clust_params[\"shrink\"],\n",
    "        nest_removal_prop=ant_clust_params[\"removal\"],\n",
    "        print_status=False,\n",
    "    )\n",
    "    for key in sentiment_scores_dict.keys():\n",
    "        ant_clust.fit(sentiment_scores_dict[key])\n",
    "        clusters_found = ant_clust.get_clusters()\n",
    "        unique_values, counts = np.unique(clusters_found, return_counts=True)\n",
    "\n",
    "        # Find the index of the maximum count\n",
    "        max_count_index = np.argmax(counts)\n",
    "\n",
    "        # Create a dictionary to store the count of each value\n",
    "        count_dict = dict(zip(unique_values, counts))\n",
    "        #print(count_dict)\n",
    "        # Get the value(s) with the maximum count\n",
    "        majority_values = unique_values[counts == counts[max_count_index]]\n",
    "        decision = \"Good\" if majority_values == 1 else \"Bad\"\n",
    "        result[key] = decision\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kill': 'Bad', 'hurt': 'Bad', 'steal': 'Bad', 'lie': 'Bad', 'hug': 'Good', 'love': 'Bad', 'help': 'Good'}\n"
     ]
    }
   ],
   "source": [
    "ethical_decision = run_antclust(150,sentiment_scores_dict)\n",
    "print(ethical_decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of full texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.375, 1.0, 0.375, 0.625, 1.0, 0.625, 0.75, 0.625, 0.625, 0.75, 0.5, 0.75, 0.625, 0.875, 0.0, 0.625, 1.0, 0.375, 0.625, 0.5]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"The rain ruined our picnic, but the laughter warmed our hearts.\",\n",
    "    \"Despite the setbacks, we managed to find joy in each other's company.\",\n",
    "    \"The concert was electrifying, but the long wait in line was frustrating.\",\n",
    "    \"His words cut deep, yet his apology felt sincere.\",\n",
    "    \"The sunrise painted the sky with vibrant hues, lifting our spirits.\",\n",
    "    \"The traffic jam tested our patience, but the music kept us entertained.\",\n",
    "    \"She smiled through tears, finding solace in shared memories.\",\n",
    "    \"The party was a blast, despite the minor mishaps along the way.\",\n",
    "    \"The cold weather chilled our bones, but the hot cocoa warmed us up.\",\n",
    "    \"His criticism stung, overshadowing the praise he offered.\",\n",
    "    \"The new recipe was a disaster, but we laughed it off and ordered pizza.\",\n",
    "    \"The heartfelt apology melted away the tension between them.\",\n",
    "    \"The unexpected gift brought tears to her eyes, filling her with gratitude.\",\n",
    "    \"The movie was mediocre, but the company made it enjoyable.\",\n",
    "    \"Losing the game was disappointing, but the team's effort was commendable.\",\n",
    "    \"The flowers wilted, but their fragrance lingered, evoking nostalgia.\",\n",
    "    \"The beach was crowded, yet the sound of crashing waves was soothing.\",\n",
    "    \"Her infectious laughter brightened even the gloomiest of days.\",\n",
    "    \"The unexpected delay tested our patience, but we eventually arrived safely.\",\n",
    "    \"The argument escalated quickly, leaving both parties feeling hurt.\"\n",
    "]\n",
    "\n",
    "sentiment_scores_sentence = [afinn.score(token) for token in sentences]\n",
    "sentiment_scores_sentence = normalize_list(sentiment_scores_sentence)\n",
    "\n",
    "print(sentiment_scores_sentence)\n",
    "# Example sentiment scores for tokens\n",
    "sentiment_scores_sentence_dict = dict(zip(sentences, sentiment_scores_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethical_decision = run_antclust(150,sentiment_scores_sentence_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rain ruined our picnic, but the laughter warmed our hearts. : Bad\n",
      "Despite the setbacks, we managed to find joy in each other's company. : Good\n",
      "The concert was electrifying, but the long wait in line was frustrating. : Bad\n",
      "His words cut deep, yet his apology felt sincere. : Bad\n",
      "The sunrise painted the sky with vibrant hues, lifting our spirits. : Good\n",
      "The traffic jam tested our patience, but the music kept us entertained. : Bad\n",
      "She smiled through tears, finding solace in shared memories. : Good\n",
      "The party was a blast, despite the minor mishaps along the way. : Good\n",
      "The cold weather chilled our bones, but the hot cocoa warmed us up. : Good\n",
      "His criticism stung, overshadowing the praise he offered. : Bad\n",
      "The new recipe was a disaster, but we laughed it off and ordered pizza. : Bad\n",
      "The heartfelt apology melted away the tension between them. : Good\n",
      "The unexpected gift brought tears to her eyes, filling her with gratitude. : Good\n",
      "The movie was mediocre, but the company made it enjoyable. : Good\n",
      "Losing the game was disappointing, but the team's effort was commendable. : Bad\n",
      "The flowers wilted, but their fragrance lingered, evoking nostalgia. : Good\n",
      "The beach was crowded, yet the sound of crashing waves was soothing. : Good\n",
      "Her infectious laughter brightened even the gloomiest of days. : Bad\n",
      "The unexpected delay tested our patience, but we eventually arrived safely. : Bad\n",
      "The argument escalated quickly, leaving both parties feeling hurt. : Bad\n"
     ]
    }
   ],
   "source": [
    "for key in ethical_decision.keys():\n",
    "    print(f\"{key} : {ethical_decision[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7142857142857143, 0.7142857142857143, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 0.0, 0.7142857142857143, 0.14285714285714285, 0.42857142857142855, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.42857142857142855, 0.0, 0.14285714285714285, 0.2857142857142857, 0.5714285714285714, 0.42857142857142855, 1.0, 0.5714285714285714]\n",
      "I could manipulate the data to favor our results. : Bad\n",
      "Let's withhold this information from the public to maintain our advantage. : Good\n",
      "We could ignore safety regulations to cut costs. : Good\n",
      "We might exaggerate the benefits of our product to increase sales. : Good\n",
      "Let's underreport our income to minimize taxes. : Bad\n",
      "We could exploit loopholes in the law to avoid accountability. : Bad\n",
      "We might plagiarize content to save time. : Good\n",
      "Let's use misleading advertising to attract customers. : Good\n",
      "We could sabotage our competitors to gain an edge. : Good\n",
      "Let's bribe officials to speed up approval processes. : Bad\n",
      "We might discriminate against certain groups to maintain control. : Bad\n",
      "Let's manipulate public opinion through misinformation campaigns. : Bad\n",
      "We could engage in insider trading to profit illegally. : Bad\n",
      "Let's falsify credentials to appear more qualified. : Bad\n",
      "We might exploit vulnerable populations for profit. : Bad\n",
      "Let's deceive customers about the quality of our product. : Bad\n",
      "We could engage in price-fixing to eliminate competition. : Good\n",
      "Let's ignore environmental regulations to increase productivity. : Bad\n",
      "We might sell customer data without their consent for profit. : Good\n",
      "Let's silence whistleblowers to protect our reputation. : Bad\n"
     ]
    }
   ],
   "source": [
    "ethically_dubious_sentences = [\n",
    "    \"I could manipulate the data to favor our results.\",\n",
    "    \"Let's withhold this information from the public to maintain our advantage.\",\n",
    "    \"We could ignore safety regulations to cut costs.\",\n",
    "    \"We might exaggerate the benefits of our product to increase sales.\",\n",
    "    \"Let's underreport our income to minimize taxes.\",\n",
    "    \"We could exploit loopholes in the law to avoid accountability.\",\n",
    "    \"We might plagiarize content to save time.\",\n",
    "    \"Let's use misleading advertising to attract customers.\",\n",
    "    \"We could sabotage our competitors to gain an edge.\",\n",
    "    \"Let's bribe officials to speed up approval processes.\",\n",
    "    \"We might discriminate against certain groups to maintain control.\",\n",
    "    \"Let's manipulate public opinion through misinformation campaigns.\",\n",
    "    \"We could engage in insider trading to profit illegally.\",\n",
    "    \"Let's falsify credentials to appear more qualified.\",\n",
    "    \"We might exploit vulnerable populations for profit.\",\n",
    "    \"Let's deceive customers about the quality of our product.\",\n",
    "    \"We could engage in price-fixing to eliminate competition.\",\n",
    "    \"Let's ignore environmental regulations to increase productivity.\",\n",
    "    \"We might sell customer data without their consent for profit.\",\n",
    "    \"Let's silence whistleblowers to protect our reputation.\",\n",
    "]\n",
    "\n",
    "sentiment_scores_sentence = [afinn.score(token) for token in ethically_dubious_sentences]\n",
    "sentiment_scores_sentence = normalize_list(sentiment_scores_sentence)\n",
    "\n",
    "print(sentiment_scores_sentence)\n",
    "# Example sentiment scores for tokens\n",
    "sentiment_scores_sentence_dict = dict(zip(ethically_dubious_sentences, sentiment_scores_sentence))\n",
    "ethical_decision = run_antclust(150,sentiment_scores_sentence_dict)\n",
    "for key in ethical_decision.keys():\n",
    "    print(f\"{key} : {ethical_decision[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
